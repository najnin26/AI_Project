{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b4972c7",
   "metadata": {},
   "source": [
    "# **Loading tools and dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bea8cd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 22:58:35.971071: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-14 22:58:36.007621: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-14 22:58:36.661469: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be3d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_data=pd.read_csv('arxiv_data_210930-054931.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0244c3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>titles</th>\n",
       "      <th>abstracts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['cs.LG']</td>\n",
       "      <td>Multi-Level Attention Pooling for Graph Neural...</td>\n",
       "      <td>Graph neural networks (GNNs) have been widely ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['cs.LG', 'cs.AI']</td>\n",
       "      <td>Decision Forests vs. Deep Networks: Conceptual...</td>\n",
       "      <td>Deep networks and decision forests (such as ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['cs.LG', 'cs.CR', 'stat.ML']</td>\n",
       "      <td>Power up! Robust Graph Convolutional Network v...</td>\n",
       "      <td>Graph convolutional networks (GCNs) are powerf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['cs.LG', 'cs.CR']</td>\n",
       "      <td>Releasing Graph Neural Networks with Different...</td>\n",
       "      <td>With the increasing popularity of Graph Neural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['cs.LG']</td>\n",
       "      <td>Recurrence-Aware Long-Term Cognitive Network f...</td>\n",
       "      <td>Machine learning solutions for pattern classif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           terms  \\\n",
       "0                      ['cs.LG']   \n",
       "1             ['cs.LG', 'cs.AI']   \n",
       "2  ['cs.LG', 'cs.CR', 'stat.ML']   \n",
       "3             ['cs.LG', 'cs.CR']   \n",
       "4                      ['cs.LG']   \n",
       "\n",
       "                                              titles  \\\n",
       "0  Multi-Level Attention Pooling for Graph Neural...   \n",
       "1  Decision Forests vs. Deep Networks: Conceptual...   \n",
       "2  Power up! Robust Graph Convolutional Network v...   \n",
       "3  Releasing Graph Neural Networks with Different...   \n",
       "4  Recurrence-Aware Long-Term Cognitive Network f...   \n",
       "\n",
       "                                           abstracts  \n",
       "0  Graph neural networks (GNNs) have been widely ...  \n",
       "1  Deep networks and decision forests (such as ra...  \n",
       "2  Graph convolutional networks (GCNs) are powerf...  \n",
       "3  With the increasing popularity of Graph Neural...  \n",
       "4  Machine learning solutions for pattern classif...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d0b25",
   "metadata": {},
   "source": [
    "# **Data Cleaning and Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a81cf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56181, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30bf0c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "terms        0\n",
       "titles       0\n",
       "abstracts    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b3cfdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>titles</th>\n",
       "      <th>abstracts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['cs.LG']</td>\n",
       "      <td>Multi-Level Attention Pooling for Graph Neural...</td>\n",
       "      <td>Graph neural networks (GNNs) have been widely ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['cs.LG', 'cs.AI']</td>\n",
       "      <td>Decision Forests vs. Deep Networks: Conceptual...</td>\n",
       "      <td>Deep networks and decision forests (such as ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['cs.LG', 'cs.CR', 'stat.ML']</td>\n",
       "      <td>Power up! Robust Graph Convolutional Network v...</td>\n",
       "      <td>Graph convolutional networks (GCNs) are powerf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['cs.LG', 'cs.CR']</td>\n",
       "      <td>Releasing Graph Neural Networks with Different...</td>\n",
       "      <td>With the increasing popularity of Graph Neural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['cs.LG']</td>\n",
       "      <td>Recurrence-Aware Long-Term Cognitive Network f...</td>\n",
       "      <td>Machine learning solutions for pattern classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56176</th>\n",
       "      <td>['cs.CV', 'cs.IR']</td>\n",
       "      <td>Mining Spatio-temporal Data on Industrializati...</td>\n",
       "      <td>Despite the growing availability of big data i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56177</th>\n",
       "      <td>['cs.LG', 'cs.AI', 'cs.CL', 'I.2.6; I.2.7']</td>\n",
       "      <td>Wav2Letter: an End-to-End ConvNet-based Speech...</td>\n",
       "      <td>This paper presents a simple end-to-end model ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56178</th>\n",
       "      <td>['cs.LG']</td>\n",
       "      <td>Deep Reinforcement Learning with Double Q-lear...</td>\n",
       "      <td>The popular Q-learning algorithm is known to o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56179</th>\n",
       "      <td>['stat.ML', 'cs.LG', 'math.OC']</td>\n",
       "      <td>Generalized Low Rank Models</td>\n",
       "      <td>Principal components analysis (PCA) is a well-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56180</th>\n",
       "      <td>['cs.LG', 'cs.AI', 'stat.ML']</td>\n",
       "      <td>Chi-square Tests Driven Method for Learning th...</td>\n",
       "      <td>SDYNA is a general framework designed to addre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56181 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             terms  \\\n",
       "0                                        ['cs.LG']   \n",
       "1                               ['cs.LG', 'cs.AI']   \n",
       "2                    ['cs.LG', 'cs.CR', 'stat.ML']   \n",
       "3                               ['cs.LG', 'cs.CR']   \n",
       "4                                        ['cs.LG']   \n",
       "...                                            ...   \n",
       "56176                           ['cs.CV', 'cs.IR']   \n",
       "56177  ['cs.LG', 'cs.AI', 'cs.CL', 'I.2.6; I.2.7']   \n",
       "56178                                    ['cs.LG']   \n",
       "56179              ['stat.ML', 'cs.LG', 'math.OC']   \n",
       "56180                ['cs.LG', 'cs.AI', 'stat.ML']   \n",
       "\n",
       "                                                  titles  \\\n",
       "0      Multi-Level Attention Pooling for Graph Neural...   \n",
       "1      Decision Forests vs. Deep Networks: Conceptual...   \n",
       "2      Power up! Robust Graph Convolutional Network v...   \n",
       "3      Releasing Graph Neural Networks with Different...   \n",
       "4      Recurrence-Aware Long-Term Cognitive Network f...   \n",
       "...                                                  ...   \n",
       "56176  Mining Spatio-temporal Data on Industrializati...   \n",
       "56177  Wav2Letter: an End-to-End ConvNet-based Speech...   \n",
       "56178  Deep Reinforcement Learning with Double Q-lear...   \n",
       "56179                        Generalized Low Rank Models   \n",
       "56180  Chi-square Tests Driven Method for Learning th...   \n",
       "\n",
       "                                               abstracts  \n",
       "0      Graph neural networks (GNNs) have been widely ...  \n",
       "1      Deep networks and decision forests (such as ra...  \n",
       "2      Graph convolutional networks (GCNs) are powerf...  \n",
       "3      With the increasing popularity of Graph Neural...  \n",
       "4      Machine learning solutions for pattern classif...  \n",
       "...                                                  ...  \n",
       "56176  Despite the growing availability of big data i...  \n",
       "56177  This paper presents a simple end-to-end model ...  \n",
       "56178  The popular Q-learning algorithm is known to o...  \n",
       "56179  Principal components analysis (PCA) is a well-...  \n",
       "56180  SDYNA is a general framework designed to addre...  \n",
       "\n",
       "[56181 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9793536f",
   "metadata": {},
   "source": [
    "# **Data Cleaning and Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "916611d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56181, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f26f2c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "terms        0\n",
       "titles       0\n",
       "abstracts    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ec439c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15054"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "547e3c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          ['cs.LG']\n",
       "1                                 ['cs.LG', 'cs.AI']\n",
       "2                      ['cs.LG', 'cs.CR', 'stat.ML']\n",
       "3                                 ['cs.LG', 'cs.CR']\n",
       "4                                          ['cs.LG']\n",
       "                            ...                     \n",
       "56176                             ['cs.CV', 'cs.IR']\n",
       "56177    ['cs.LG', 'cs.AI', 'cs.CL', 'I.2.6; I.2.7']\n",
       "56178                                      ['cs.LG']\n",
       "56179                ['stat.ML', 'cs.LG', 'math.OC']\n",
       "56180                  ['cs.LG', 'cs.AI', 'stat.ML']\n",
       "Name: terms, Length: 56181, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data['terms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e153f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels : ['cs.LG' 'cs.AI' 'cs.CR' ... 'D.1.3; G.4; I.2.8; I.2.11; I.5.3; J.3'\n",
      " '68T07, 68T45, 68T10, 68T50, 68U35' 'I.2.0; G.3']\n",
      "lenght : 1177\n"
     ]
    }
   ],
   "source": [
    "# getting unique labels\n",
    "labels_column = arxiv_data['terms'].apply(literal_eval)\n",
    "labels = labels_column.explode().unique()\n",
    "print(\"labels :\",labels)\n",
    "print(\"lenght :\",len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee54d7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 41105 rows in the deduplicated dataset.\n",
      "2503\n",
      "3401\n"
     ]
    }
   ],
   "source": [
    "# remove duplicate entries based on the \"titles\" (terms) column\n",
    "# This filters the DataFrame, keeping only the rows where the titles are not duplicated.\n",
    "arxiv_data = arxiv_data[~arxiv_data['titles'].duplicated()]\n",
    "print(f\"There are {len(arxiv_data)} rows in the deduplicated dataset.\")\n",
    "# There are some terms with occurrence as low as 1.\n",
    "print(sum(arxiv_data['terms'].value_counts()==1))\n",
    "# how many unique terms\n",
    "print(arxiv_data['terms'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8ce112a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38602, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering the rare terms. (it keeps only those rows where the \"terms\" value occurs more than once in the original DataFrame.)\n",
    "arxiv_data_filtered = arxiv_data.groupby('terms').filter(lambda x: len(x) > 1)\n",
    "arxiv_data_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e8d90cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['cs.LG']), list(['cs.LG', 'cs.AI']),\n",
       "       list(['cs.LG', 'cs.CR', 'stat.ML'])], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It evaluates the given string containing a Python literal or container display (e.g., a list or dictionary) and returns the corresponding Python object.\n",
    "arxiv_data_filtered['terms'] = arxiv_data_filtered['terms'].apply(lambda x: literal_eval(x))\n",
    "arxiv_data_filtered['terms'].values[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984cbfb4",
   "metadata": {},
   "source": [
    "# **train and test split.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ade1640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training set: 34741\n",
      "Number of rows in validation set: 1930\n",
      "Number of rows in test set: 1931\n"
     ]
    }
   ],
   "source": [
    "test_split = 0.1\n",
    "\n",
    "# Initial train and test split.\n",
    "# The stratify parameter ensures that the splitting is done in a way that preserves the same distribution of labels (terms) in both the training and test sets.\n",
    "train_df, test_df = train_test_split(arxiv_data_filtered,test_size=test_split,stratify=arxiv_data_filtered[\"terms\"].values,)\n",
    "\n",
    "# Splitting the test set further into validation\n",
    "# and new test sets.\n",
    "val_df = test_df.sample(frac=0.5)\n",
    "test_df.drop(val_df.index, inplace=True)\n",
    "\n",
    "print(f\"Number of rows in training set: {len(train_df)}\")\n",
    "print(f\"Number of rows in validation set: {len(val_df)}\")\n",
    "print(f\"Number of rows in test set: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8d7e94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      "\n",
      "['[UNK]', 'cs.CV', 'cs.LG', 'stat.ML', 'cs.AI', 'eess.IV', 'cs.RO', 'cs.CL', 'cs.NE', 'cs.GR', 'cs.CR', 'math.OC', 'eess.SP', 'cs.SI', 'cs.MM', 'cs.SY', 'cs.IR', 'eess.SY', 'cs.MA', 'cs.HC', 'math.IT', 'cs.IT', 'cs.DC', 'stat.AP', 'cs.CY', 'stat.ME', 'stat.TH', 'math.ST', 'eess.AS', 'cs.SD', 'cs.DS', 'q-bio.QM', 'q-bio.NC', 'cs.CG', 'stat.CO', 'cs.GT', 'cs.NI', 'math.NA', 'cs.SE', 'cs.NA', 'I.2.6', 'physics.chem-ph', 'cs.DB', 'physics.comp-ph', 'cond-mat.dis-nn', 'q-bio.BM', 'cs.LO', 'math.PR', 'cs.PL', '68T45', 'cs.AR', 'physics.data-an', 'quant-ph', 'I.2.10', 'cs.CE', 'cond-mat.stat-mech', 'q-fin.ST', 'I.4.6', 'physics.ao-ph', 'math.DS', 'cs.CC', '68T05', 'physics.soc-ph', 'physics.med-ph', 'cs.PF', 'econ.EM', 'cs.DM', 'I.4.8', 'q-bio.GN', 'astro-ph.IM', 'physics.geo-ph', 'physics.flu-dyn', 'math.AT', 'hep-ex', 'I.4', '68U10', 'q-fin.TR', 'cs.FL', 'I.5.4', 'I.2', 'physics.optics', 'cond-mat.mtrl-sci', 'I.4.9', '68T10', 'I.4; I.5', '68T07', 'q-fin.CP', 'math.AP', 'I.2.6; I.2.8', '68T01', '65D19', 'q-bio.PE', 'physics.app-ph', 'nlin.CD', 'math.CO', 'cs.MS', 'I.4.5', 'I.2.6; I.5.1', 'I.2.10; I.4; I.5', 'I.2.0; I.2.6', '68U01', 'q-fin.GN', 'hep-ph', 'cs.SC', 'cs.ET', 'K.3.2', 'I.2; I.5', 'I.2.8', 'I.2.10; I.4.8', '68T30', 'q-fin.EC', 'q-bio.MN', 'econ.GN', 'I.4.9; I.5.4', 'I.4.0', 'I.2; I.4; I.5', 'I.2.6; I.2.7', '68T99', '68Q32', '68', '62H30', 'q-fin.RM', 'q-fin.PM', 'q-bio.TO', 'q-bio.OT', 'physics.plasm-ph', 'physics.class-ph', 'physics.bio-ph', 'nlin.AO', 'math.SP', 'math.MP', 'math.LO', 'math.FA', 'math-ph', 'cs.DL', 'cond-mat.soft', 'I.5.2', 'I.4.6; I.4.8', 'I.4.4', 'I.4.3', 'I.4.1', 'I.3.7', 'I.2; J.2', 'I.2; I.2.6; I.2.7', 'I.2.7', 'I.2.6; I.5.4', 'I.2.6; I.2.9', 'I.2.6; I.2.7; H.3.1; H.3.3', 'I.2.6; I.2.10', 'I.2.6, I.5.4', 'I.2.1; J.3', 'I.2.10; I.5.1; I.4.8', 'I.2.10; I.4.8; I.5.4', 'I.2.10; I.2.6', 'I.2.1', 'H.3.1; I.2.6; I.2.7', 'H.3.1; H.3.3; I.2.6; I.2.7', 'G.3', 'F.2.2; I.2.7', 'E.5; E.4; E.2; H.1.1; F.1.1; F.1.3', '68Txx', '62H99', '62H35', '60L10, 60L20', '14J60 (Primary) 14F05, 14J26 (Secondary)']\n"
     ]
    }
   ],
   "source": [
    "# creates a TensorFlow RaggedTensor (terms) from the values in the \"terms\" column of the train_df DataFrame. A RaggedTensor is a tensor with non-uniform shapes\n",
    "terms = tf.ragged.constant(train_df['terms'].values)\n",
    "# This line creates a StringLookup layer in TensorFlow. The purpose of this layer is to map strings to integer indices and vice versa. The output_mode=\"multi_hot\" indicates that the layer will output a multi-hot encoded representation of the input strings.\n",
    "lookup = tf.keras.layers.StringLookup(output_mode='multi_hot')\n",
    "# This step adapts the StringLookup layer to the unique values in the \"terms\" column, building the vocabulary.\n",
    "lookup.adapt(terms)\n",
    "# retrieve vocabulary\n",
    "vocab = lookup.get_vocabulary()\n",
    "\n",
    "print(\"Vocabulary:\\n\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6912fe82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: ['cs.CV']\n",
      "Label-binarized representation: [[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "sample_label = train_df[\"terms\"].iloc[0]\n",
    "print(f\"Original label: {sample_label}\")\n",
    "\n",
    "label_binarized = lookup([sample_label])\n",
    "print(f\"Label-binarized representation: {label_binarized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1653b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_seqlen: Maximum sequence length. It indicates the maximum length allowed for sequences.\n",
    "max_seqlen = 150\n",
    "#batch_size: Batch size. It specifies the number of samples to use in each iteration.\n",
    "batch_size = 128\n",
    "#padding_token: A token used for padding sequences.\n",
    "padding_token = \"<pad>\"\n",
    "#auto = tf.data.AUTOTUNE: auto is assigned the value tf.data.AUTOTUNE,\n",
    "auto = tf.data.AUTOTUNE\n",
    "\n",
    "def make_dataset(dataframe, is_train=True):\n",
    "    # creating sequences of labesls\n",
    "    labels = tf.ragged.constant(dataframe[\"terms\"].values)\n",
    "    #This line uses the previously defined lookup layer to convert the ragged tensor of labels into a binarized representation. The resulting label_binarized is a NumPy array.\n",
    "    label_binarized = lookup(labels).numpy()\n",
    "    # creating sequences of text.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dataframe[\"abstracts\"].values, label_binarized))\n",
    "    # shuffling data basis on condition\n",
    "    dataset = dataset.shuffle(batch_size * 10) if is_train else dataset\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0437583",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train_df, is_train=True)\n",
    "validation_dataset = make_dataset(val_df, is_train=False)\n",
    "test_dataset = make_dataset(test_df, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a51280b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract: b'Road extraction is an essential step in building autonomous navigation\\nsystems. Detecting road segments is challenging as they are of varying widths,\\nbifurcated throughout the image, and are often occluded by terrain, cloud, or\\nother weather conditions. Using just convolution neural networks (ConvNets) for\\nthis problem is not effective as it is inefficient at capturing distant\\ndependencies between road segments in the image which is essential to extract\\nroad connectivity. To this end, we propose a Spatial and Interaction Space\\nGraph Reasoning (SPIN) module which when plugged into a ConvNet performs\\nreasoning over graphs constructed on spatial and interaction spaces projected\\nfrom the feature maps. Reasoning over spatial space extracts dependencies\\nbetween different spatial regions and other contextual information. Reasoning\\nover a projected interaction space helps in appropriate delineation of roads\\nfrom other topographies present in the image. Thus, SPIN extracts long-range\\ndependencies between road segments and effectively delineates roads from other\\nsemantics. We also introduce a SPIN pyramid which performs SPIN graph reasoning\\nacross multiple scales to extract multi-scale features. We propose a network\\nbased on stacked hourglass modules and SPIN pyramid for road segmentation which\\nachieves better performance compared to existing methods. Moreover, our method\\nis computationally efficient and significantly boosts the convergence speed\\nduring training, making it feasible for applying on large-scale high-resolution\\naerial images. Code available at:\\nhttps://github.com/wgcban/SPIN_RoadMapper.git.'\n",
      "Label(s): ['cs.CV' 'cs.LG' 'cs.RO']\n",
      " \n",
      "Abstract: b'Adversarial examples are inputs to machine learning models designed to cause\\nthe model to make a mistake. They are useful for understanding the shortcomings\\nof machine learning models, interpreting their results, and for regularisation.\\nIn NLP, however, most example generation strategies produce input text by using\\nknown, pre-specified semantic transformations, requiring significant manual\\neffort and in-depth understanding of the problem and domain. In this paper, we\\ninvestigate the problem of automatically generating adversarial examples that\\nviolate a set of given First-Order Logic constraints in Natural Language\\nInference (NLI). We reduce the problem of identifying such adversarial examples\\nto a combinatorial optimisation problem, by maximising a quantity measuring the\\ndegree of violation of such constraints and by using a language model for\\ngenerating linguistically-plausible examples. Furthermore, we propose a method\\nfor adversarially regularising neural NLI models for incorporating background\\nknowledge. Our results show that, while the proposed method does not always\\nimprove results on the SNLI and MultiNLI datasets, it significantly and\\nconsistently increases the predictive accuracy on adversarially-crafted\\ndatasets -- up to a 79.6% relative improvement -- while drastically reducing\\nthe number of background knowledge violations. Furthermore, we show that\\nadversarial examples transfer among model architectures, and that the proposed\\nadversarial training procedure improves the robustness of NLI models to\\nadversarial examples.'\n",
      "Label(s): ['cs.LG' 'stat.ML' 'cs.AI' 'cs.CL']\n",
      " \n",
      "Abstract: b'The task of crowd counting in varying density scenes is an extremely\\ndifficult challenge due to large scale variations. In this paper, we propose a\\nnovel dual path multi-scale fusion network architecture with attention\\nmechanism named SFANet that can perform accurate count estimation as well as\\npresent high-resolution density maps for highly congested crowd scenes. The\\nproposed SFANet contains two main components: a VGG backbone convolutional\\nneural network (CNN) as the front-end feature map extractor and a dual path\\nmulti-scale fusion networks as the back-end to generate density map. These dual\\npath multi-scale fusion networks have the same structure, one path is\\nresponsible for generating attention map by highlighting crowd regions in\\nimages, the other path is responsible for fusing multi-scale features as well\\nas attention map to generate the final high-quality high-resolution density\\nmaps. SFANet can be easily trained in an end-to-end way by dual path joint\\ntraining. We have evaluated our method on four crowd counting datasets\\n(ShanghaiTech, UCF CC 50, UCSD and UCF-QRNF). The results demonstrate that with\\nattention mechanism and multi-scale feature fusion, the proposed SFANet\\nachieves the best performance on all these datasets and generates better\\nquality density maps compared with other state-of-the-art approaches.'\n",
      "Label(s): ['cs.CV']\n",
      " \n",
      "Abstract: b'Transformers have offered a new methodology of designing neural networks for\\nvisual recognition. Compared to convolutional networks, Transformers enjoy the\\nability of referring to global features at each stage, yet the attention module\\nbrings higher computational overhead that obstructs the application of\\nTransformers to process high-resolution visual data. This paper aims to\\nalleviate the conflict between efficiency and flexibility, for which we propose\\na specialized token for each region that serves as a messenger (MSG). Hence, by\\nmanipulating these MSG tokens, one can flexibly exchange visual information\\nacross regions and the computational complexity is reduced. We then integrate\\nthe MSG token into a multi-scale architecture named MSG-Transformer. In\\nstandard image classification and object detection, MSG-Transformer achieves\\ncompetitive performance and the inference on both GPU and CPU is accelerated.\\nThe code will be available at https://github.com/hustvl/MSG-Transformer.'\n",
      "Label(s): ['cs.CV' 'cs.LG']\n",
      " \n",
      "Abstract: b'Surface reconstruction from point clouds is a fundamental problem in the\\ncomputer vision and graphics community. Recent state-of-the-arts solve this\\nproblem by individually optimizing each local implicit field during inference.\\nWithout considering the geometric relationships between local fields, they\\ntypically require accurate normals to avoid the sign conflict problem in\\noverlapped regions of local fields, which severely limits their applicability\\nto raw scans where surface normals could be unavailable. Although SAL breaks\\nthis limitation via sign-agnostic learning, further works still need to explore\\nhow to extend this technique for local shape modeling. To this end, we propose\\nto learn implicit surface reconstruction by sign-agnostic optimization of\\nconvolutional occupancy networks, to simultaneously achieve advanced\\nscalability to large-scale scenes, generality to novel shapes, and\\napplicability to raw scans in a unified framework. Concretely, we achieve this\\ngoal by a simple yet effective design, which further optimizes the pre-trained\\noccupancy prediction networks with an unsigned cross-entropy loss during\\ninference. The learning of occupancy fields is conditioned on convolutional\\nfeatures from an hourglass network architecture. Extensive experimental\\ncomparisons with previous state-of-the-arts on both object-level and\\nscene-level datasets demonstrate the superior accuracy of our approach for\\nsurface reconstruction from un-orientated point clouds. The code is available\\nat https://github.com/tangjiapeng/SA-ConvONet.'\n",
      "Label(s): ['cs.CV']\n",
      " \n"
     ]
    }
   ],
   "source": [
    "def invert_multi_hot(encoded_labels):\n",
    "    hot_indeces=np.argwhere(encoded_labels==1.0)[...,0]\n",
    "    return np.take(vocab,hot_indeces)\n",
    "\n",
    "text_batch, label_batch = next(iter(train_dataset))\n",
    "for i, text in enumerate(text_batch[:5]):\n",
    "    label = label_batch[i].numpy()[None, ...]\n",
    "    print(f\"Abstract: {text}\")\n",
    "    print(f\"Label(s): {invert_multi_hot(label[0])}\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cec32f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158907\n"
     ]
    }
   ],
   "source": [
    "# Creating vocabulary with uniques words\n",
    "vocabulary = set()\n",
    "train_df[\"abstracts\"].str.lower().str.split().apply(vocabulary.update)\n",
    "vocabulary_size = len(vocabulary)\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f599fa3a",
   "metadata": {},
   "source": [
    "# **Text Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed2b9e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 22:59:05.101190: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "text_vectorizer = layers.TextVectorization(max_tokens=vocabulary_size,ngrams=2,output_mode=\"tf_idf\")\n",
    "# `TextVectorization` layer needs to be adapted as per the vocabulary from our training set.\n",
    "text_vectorizer.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23beccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto).prefetch(auto)\n",
    "validation_dataset = validation_dataset.map(lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto).prefetch(auto)\n",
    "test_dataset = test_dataset.map(lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto).prefetch(auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ca23fa",
   "metadata": {},
   "source": [
    "# **model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ad252aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 789ms/step - binary_accuracy: 0.9503 - loss: 0.1183 - val_binary_accuracy: 0.9948 - val_loss: 0.0182\n",
      "Epoch 2/20\n",
      "\u001b[1m 60/272\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:43\u001b[0m 771ms/step - binary_accuracy: 0.9939 - loss: 0.0225"
     ]
    }
   ],
   "source": [
    "# creating shallow_mlp_model  (MLP)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Creating shallow_mlp_model (MLP) with dropout layers\n",
    "model1 = keras.Sequential([\n",
    "    # First hidden layer: 512 neurons, ReLU activation function, with dropout.\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),  # Adding dropout for regularization.\n",
    "\n",
    "    # Second hidden layer: 256 neurons, ReLU activation function, with dropout.\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),  # Adding dropout for regularization.\n",
    "\n",
    "    # Output layer: The number of neurons equals the vocabulary size (output vocabulary of the StringLookup layer), with a sigmoid activation function.\n",
    "    layers.Dense(lookup.vocabulary_size(), activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model1.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "# Add early stopping\n",
    "# Number of epochs with no improvement after which training will be stopped.\n",
    "# Restore weights from the epoch with the best value of the monitored quantity.\n",
    "early_stopping = EarlyStopping(patience=5,restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "# Add early stopping callback.verbose=1\n",
    "history = model1.fit(train_dataset,validation_data=validation_dataset,epochs=20,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6040655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting loss\n",
    "def plot_result(item):\n",
    "    plt.plot(history.history[item], label=item)\n",
    "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(item)\n",
    "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_result(\"loss\")\n",
    "plot_result(\"binary_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c11a60b",
   "metadata": {},
   "source": [
    "# **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06a0717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28137e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7540d3f",
   "metadata": {},
   "source": [
    "# **Save Model and Text Vectorizer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb86a342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f1c4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e9b1246",
   "metadata": {},
   "source": [
    "# **Load Model and Text Vectorizer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a312faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f54cbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87423ad0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd86bbd4",
   "metadata": {},
   "source": [
    "# **Model Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282b22eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6278224b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e6ff29b",
   "metadata": {},
   "source": [
    "# ** =======Section 2========**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b38235",
   "metadata": {},
   "source": [
    "# **Recommendation System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9d9830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_data.drop(columns = [\"terms\",\"abstracts\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ad83770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multi-Level Attention Pooling for Graph Neural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Forests vs. Deep Networks: Conceptual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Power up! Robust Graph Convolutional Network v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Releasing Graph Neural Networks with Different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Recurrence-Aware Long-Term Cognitive Network f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56176</th>\n",
       "      <td>Mining Spatio-temporal Data on Industrializati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56177</th>\n",
       "      <td>Wav2Letter: an End-to-End ConvNet-based Speech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56178</th>\n",
       "      <td>Deep Reinforcement Learning with Double Q-lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56179</th>\n",
       "      <td>Generalized Low Rank Models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56180</th>\n",
       "      <td>Chi-square Tests Driven Method for Learning th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56181 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  titles\n",
       "0      Multi-Level Attention Pooling for Graph Neural...\n",
       "1      Decision Forests vs. Deep Networks: Conceptual...\n",
       "2      Power up! Robust Graph Convolutional Network v...\n",
       "3      Releasing Graph Neural Networks with Different...\n",
       "4      Recurrence-Aware Long-Term Cognitive Network f...\n",
       "...                                                  ...\n",
       "56176  Mining Spatio-temporal Data on Industrializati...\n",
       "56177  Wav2Letter: an End-to-End ConvNet-based Speech...\n",
       "56178  Deep Reinforcement Learning with Double Q-lear...\n",
       "56179                        Generalized Low Rank Models\n",
       "56180  Chi-square Tests Driven Method for Learning th...\n",
       "\n",
       "[56181 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f8e3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "056f3632",
   "metadata": {},
   "source": [
    "# **Sentence Transformers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13b65715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najnin/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer,util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0e3c301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najnin/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aa10c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = arxiv_data['titles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae7cde06",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f83d5ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06643411, -0.04954598,  0.06388082, ...,  0.00106297,\n",
       "        -0.12156384, -0.06962778],\n",
       "       [ 0.0921226 , -0.07606938,  0.06572865, ..., -0.0856517 ,\n",
       "        -0.09266545,  0.00725295],\n",
       "       [-0.08162681,  0.02428927,  0.01888743, ...,  0.00806166,\n",
       "        -0.05129531, -0.05873994],\n",
       "       ...,\n",
       "       [-0.09695324,  0.00057095,  0.07726481, ..., -0.01443811,\n",
       "        -0.04748208,  0.06130565],\n",
       "       [ 0.00768868, -0.10124182,  0.08909856, ..., -0.08199871,\n",
       "        -0.05649743,  0.09007054],\n",
       "       [ 0.06078521, -0.08312801, -0.00907773, ..., -0.03148183,\n",
       "         0.0571311 ,  0.0569689 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36eafd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56181, 384)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ac5188",
   "metadata": {},
   "source": [
    "# **Print the embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1eb976d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Multi-Level Attention Pooling for Graph Neural Networks: Unifying Graph Representations with Multiple Localities\n",
      "Embedding length: 384\n",
      "\n",
      "Sentence: Decision Forests vs. Deep Networks: Conceptual Similarities and Empirical Differences at Small Sample Sizes\n",
      "Embedding length: 384\n",
      "\n",
      "Sentence: Power up! Robust Graph Convolutional Network via Graph Powering\n",
      "Embedding length: 384\n",
      "\n",
      "Sentence: Releasing Graph Neural Networks with Differential Privacy Guarantees\n",
      "Embedding length: 384\n",
      "\n",
      "Sentence: Recurrence-Aware Long-Term Cognitive Network for Explainable Pattern Classification\n",
      "Embedding length: 384\n",
      "\n",
      "Sentence: Lifelong Graph Learning\n",
      "Embedding length: 384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "\n",
    "for sentence,embedding in zip(sentences,embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding length:\", len(embedding)) # list of floats\n",
    "    print(\"\")\n",
    "    if c>=5:\n",
    "        break\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78fc789",
   "metadata": {},
   "source": [
    "# **Save files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b79c045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"Models/embeddings.pkl\",'wb') as f:\n",
    "    pickle.dump(embeddings,f)\n",
    "    \n",
    "with open('Models/sentences.pkl', 'wb') as f:\n",
    "    pickle.dump(sentences, f)\n",
    "    \n",
    "with open('Models/rec_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1ad793",
   "metadata": {},
   "source": [
    "# **Recommendation for similar papers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1adb2efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load save files\n",
    "embeddings = pickle.load(open('Models/embeddings.pkl','rb'))\n",
    "sentences = pickle.load(open('Models/sentences.pkl','rb'))\n",
    "rec_model = pickle.load(open('Models/rec_model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dfaeb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def recommendation(input_paper):\n",
    "    # Calculate cosine similarity scores between the embeddings of input_paper and all papers in the dataset.\n",
    "    cosine_scores = util.cos_sim(embeddings, rec_model.encode(input_paper))\n",
    "    \n",
    "    # Get the indices of the top-k most similar papers based on cosine similarity.\n",
    "    top_similar_papers = torch.topk(cosine_scores, dim=0, k=5, sorted=True)\n",
    "                                 \n",
    "    # Retrieve the titles of the top similar papers.\n",
    "    papers_list = []\n",
    "    for i in top_similar_papers.indices:\n",
    "        papers_list.append(sentences[i.item()])\n",
    "    \n",
    "    return papers_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09ed8304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We recommend to read this paper............\n",
      "=============================================\n",
      "Attention that does not Explain Away\n",
      "Attention that does not Explain Away\n",
      "Attention that does not Explain Away\n",
      "Area Attention\n",
      "Area Attention\n"
     ]
    }
   ],
   "source": [
    "# exampel usage 1: (use this paper as input (BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding))\n",
    "# exampel usage 2: (use this paper as input (Review of deep learning: concepts, CNN architectures, challenges, applications, future directions))\n",
    "\n",
    "input_paper = input(\"Enter the title of any paper you like \")\n",
    "\n",
    "recommend_papers = recommendation(input_paper)\n",
    "\n",
    "\n",
    "print(\"We recommend to read this paper............\")\n",
    "print(\"=============================================\")\n",
    "for paper in recommend_papers:\n",
    "    print(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8ff11c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
